{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r5SEFD9D4KK"
   },
   "source": [
    "# Trabalho de casa 02: Regressão linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruções gerais:** Sua submissão deve conter: \n",
    "1. Um \"ipynb\" com seu código e as soluções dos problemas\n",
    "2. Uma versão pdf do ipynb\n",
    "\n",
    "Caso você opte por resolver as questões de \"papel e caneta\" em um editor de $\\LaTeX$ externo, o inclua no final da versão pdf do 'ipynb'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios computacionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bC12OuanDqSJ"
   },
   "source": [
    "**Exercício 1.** Deixamos à sua disposição o dataset [\"California Housing\"](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html#sklearn.datasets.fetch_california_housing), dividido em treino, teste e validação.\n",
    "O modelo que você utilizará para aproximar a relação funcional entre as features e as labels é o modelo linear, i.e., $\\boldsymbol{y} = X\\theta$.\n",
    "Entretanto, você deve estimar seus parâmetros (minimizando o *mean squared error*) com **dois algoritmos diferentes**.\n",
    "Uma implementação deve estimar $\\theta$ por meio de **Stochastic Gradient Descent (SGD)** e, a outra, por meio de **Ordinary Least Squares (OLS)**, ou seja, utilizar a solução em fórmula fechada vista em aula.\n",
    "\n",
    "Para o SGD, o ponto inicial deve ser escolhido aleatoriamente e o algoritmo deve parar quando a norma da diferença entre duas estimativas consecutivas de $\\theta$ for menor do que um $\\varepsilon > 0$ previamente especificado.\n",
    "Para o experimento a seguir, fixe $\\varepsilon$ em um valor pequeno (por exemplo, alguma potência de $1/10$) para a qual o algoritmo convirja no máximo em alguns minutos para uma solução com perda pequena.\n",
    "\n",
    "Para diferentes tamanhos de minibatch (por exemplo $\\{2^{j}: 1 \\leq j \\leq 7\\}$), plote um gráfico representando o valor da perda $ L(\\hat{\\theta}) = \\frac{1}{n} \\lVert X \\hat{\\theta} - \\mathbf{y} \\rVert^{2}$ no conjunto de validação em função do número de epochs. Mostre também o valor ótimo obtido com OLS. Comente os resultados e o efeito tamanho do minibatch, e.g., no tempo de treinamento. Reporte valores nos conjuntos de treino, validação e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "s7ruzqo6EDZx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "features, labels = fetch_california_housing(return_X_y=True)\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, labels, test_size=0.25\n",
    ")\n",
    "features_train, features_validation, labels_train, labels_validation = train_test_split(\n",
    "    features_train, labels_train, test_size=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aERbmmnqDlYc"
   },
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXkMBbkNTd6i"
   },
   "source": [
    "**Exercício 2.** Agora, utilizando ainda o mesmo dataset da questão anterior, você deve implementar uma **Rede RBF** com função de base Gaussiana (veja as notas de aula).\n",
    "Para os centróides, utilize o output de um modelo de clusterização por K médias, por meio da função que disponibilizamos, como a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-K82Fm4OTfGr",
    "outputId": "ce844ded-b104-4e1b-ca13-3f2ddb81cd57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.]\n",
      " [10.  2.]]\n"
     ]
    }
   ],
   "source": [
    "def k_means_factory(n_clusters: int) -> KMeans:\n",
    "    return KMeans(n_clusters=n_clusters, n_init=\"auto\")\n",
    "\n",
    "k_means_model = k_means_factory(n_clusters=2)\n",
    "dumb_data = np.array(\n",
    "    [[1, 2],\n",
    "     [1, 4],\n",
    "     [1, 0],\n",
    "     [10, 2],\n",
    "     [10, 4],\n",
    "     [10, 0]]\n",
    ")\n",
    "k_means_model.fit(dumb_data)\n",
    "cluster_centers = k_means_model.cluster_centers_\n",
    "print(cluster_centers) # Shape (n_clusters, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f9twmSXVq05"
   },
   "source": [
    "Para determinar o melhor valor de $k$ para o algoritmo de clusterização, treine o modelo (usando a fórmula de OLS) com diferentes valores e escolha o que possuir o menor erro de validação. Faça um gráfico mostrando o valor do erro de validação para diferentes valores de $k$. Mostre também a performance do modelo escolhido no conjunto de teste. Compare com o modelo linear simples da questão anterior. Discuta os resultados.\n",
    "\n",
    "Para definir o valor do hiper-parâmetro $\\gamma$, use a seguinte heurística --- que pode ser achado no livro \"Neural Networks\", por Simon Haykin:\n",
    "\n",
    "$$\n",
    "\\gamma = \\frac{1}{d_\\text{max}^2},\n",
    "$$\n",
    "\n",
    "onde $d_\\text{max}$ é a maior distância entre um par de centróides. Note que o valor costuma mudar para $k$'s diferentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seu código aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvACUfsQWm11"
   },
   "source": [
    "# Exercícios de \"papel e caneta\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 1.** Deixe que $X \\in \\mathbb{R}^{N\\times D}$, $c>0$ e $I$ denote a matriz identidade de dimensão $N$.\n",
    " Mostre que $X^\\intercal X + c I$ possui inversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 2.** Deixe que $X \\in \\mathbb{R}^{N\\times D}$ seja uma matriz contendo os exemplos de treinamento (um por linha) e que $y\\in \\mathbb{R}^N$ seja um vetor coluna dos outputs observados para cada vetor de input em suas linhas. Na aula, derivamos a solução de mínimos quadrados ordinários (OLS). Use o mesmo raciocínio para resolver achar o vetor de pesos ${\\theta}$ que minimiza:\n",
    " \n",
    "$$ \\|X \\theta - y\\|_2^2 + c \\|\\theta\\|_2^2,$$\n",
    "\n",
    "onde $c>0$ é uma constante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercício 3.** Em algumas situações, temos muito mais features que amostras ($D \\gg N$). Esse tipo de cenário é comum, e.g., na análise de dados genômicos. Nesse caso, costumam existir infinitas combinações lineares das features que expressam o vetor de saídas $y$. Portanto, precisamos de algum critério para escolher um deles. Uma abordagem possível, é escolher o vetor de pesos $\\theta$ que possua menor norma L2.\n",
    "Com isso em mente, derive a solução que minimiza $\\|\\theta\\|_2^2$ e respeita $X \\theta = y$. Assuma que as linhas de $X$ são linearmente independentes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
